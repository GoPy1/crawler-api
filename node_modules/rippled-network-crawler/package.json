{
  "name": "rippled-network-crawler",
  "version": "0.3.0",
  "description": "command line interface to crawl a rippled network",
  "license": "ISC",
  "main": "index.js",
  "scripts": {
    "test": "mocha test/"
  },
  "author": {
    "name": "Souren Papazian"
  },
  "dependencies": {
    "bluebird": "^2.9.27",
    "chai": "^3.0.0",
    "check-types": "^3.3.0",
    "commander": "^2.8.1",
    "geoip-lite": "^1.1.6",
    "lodash": "^3.7.0",
    "mocha": "^2.2.5",
    "moment": "2.10.3",
    "nconf": "^0.7.1",
    "pg": "^4.4.0",
    "pg-hstore": "^2.3.2",
    "request": "^2.55.0",
    "ripple-lib": "^0.12.3",
    "sequelize": "^3.3.0"
  },
  "bin": {
    "rippled-network-crawler": "./index.js"
  },
  "directories": {
    "test": "test"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/SourenP/rippled-network-crawler.git"
  },
  "keywords": [
    "ripple",
    "crawler",
    "rippled"
  ],
  "bugs": {
    "url": "https://github.com/SourenP/rippled-network-crawler/issues"
  },
  "homepage": "https://github.com/SourenP/rippled-network-crawler#readme",
  "readme": "# Rippled Network Crawler\n\nThis crawls the ripple network,\nvia making requests to the /crawl endpoint of each peer it can connect to, \nstarting from an entry point. Some peers may know, and publish (perhaps errantly\n.. ), the ip associated with a peer, while others don't. We merge the points of\nview of each peer, collecting a dict of data, keyed by ip address.\n\nThis maps out the connections between all rippled servers (not necessarily UNLS)\nwho (for the most part) don't even participate in Consensus or at least don't \nhave any say in influencing the outcome of a transaction on mainnet. \n\n## Installation\n\n```\nnpm install -g rippled-network-crawler\n```\n\n\n## Usage\n\nTo list program options and commands run `--help or -h`\n\n```\n$ rippled-network-crawler --help\n\n  Usage: rippled-network-crawler [options] [command]\n\n\n  Commands:\n\n    enter <ipp>                     Crawl ipp and its peers recursively\n    selective <ipp> [otherIpps...]  Crawl specified ipps without expanding crawl to peers\n    prior <dbUrl>                   Crawl selectively on ipps from latest crawl in the database\n    info <dbUrl> <id>               Get information about a crawl in the database by id\n    graphify <dbUrl> <id>           Get a json representing a d3 graph of a crawl by id\n\n  Options:\n\n    -h, --help           output usage information\n    -V, --version        output the version number\n    -m, --max <count>    Max number of http requests to have open at once, default 100\n    -r, --readable       Output json with four space indentation\n    -s, --store <dbUrl>  stores crawl output into the database specified (quietly)\n    -q, --quiet          Only output crawl json, all logging is ignored\n    -l, --logsql         Log all sequelize queries and ddl\n```\n\n## Output structure\n\n`crawl.js` outputs a stringified json in the following format:\n\n|   Field    |    Description           | Type   |\n|------------|--------------------------|--------|\n| start      | Crawl start time         | date   |\n| end        | Crawl end time           | date   |\n| entry      | Crawl entry ip:port      | string |\n| data       | Raw data collected       | array  |\n| errors     | Errors                   | array  |\n\n### Example output\n\n```json\n    {\n        \"start\" : \"2015-06-18T16:48:42-07:00\",\n        \"end\" : \"2015-06-18T16:48:48-07:00\",\n        \"entry\" : \"162.217.98.90:51235\",\n        \"data\" : [\n            {   \n                \"162.217.98.90:51235\" :  response\n            },\n            {\n                \"72.251.233.165:51235\" : response\n            },\n            {\n                ...\n            }\n        ],\n        \"errors\" : [\n            { \"98.167.119.231:51235\" : { \"code\": \"ECONNRESET\" } },\n            { \"52.4.169.56:51235\" :  { \"code\": \"ECONNREFUSED\",\n                                       \"errno\": \"ECONNREFUSED\",\n                                       \"syscall\": \"connect\" } \n            },\n            ...\n        ]\n    }\n```\n\nResponse format described [here](#response).\n\n## Schema\n\n### crawl\n\n|   Column   |           Type           |\n|------------|--------------------------|\n| id         | bigint                   |\n| start_at   | timestamp with time zone |\n| end_at     | timestamp with time zone |\n| entry_ipp  | string                   |\n| data       | json                     |\n| exceptions | json                     |\n| created_at | timestamp with time zone |\n| updated_at | timestamp with time zone |\n\n## Visualize\n\nThe `graphify` command can be used to produce a json which can be\nvisualized with `misc/index.html`. Note that `index.html` looks for a file\ncalled `graph.json` in its same directory.\n\nNode color is indicative version.\n\nNode size is indicative of out going and incoming connection count.\n\n``` bash\nnpm install http-server -g\nrippled-network-crawler graphify $DATABASE_URL 1 > misc/graph.json\ncd misc/\nhttp-server -o\n```\n\n## /crawl response format <a id=\"response\"></a>\n\nAs of the time of writing, there were various versions of rippled on the network\nand not all of them return information formatted in the same way, so some\nnormalisation must be done. Also, some fields aren't always published (like in\nthe case of `ip`). The public_key is returned in base64, so to match public keys\nencoded in base58 and saved as a string elsewhere, they must be normalised.\n\nThe top level structure of the response is as so:\n\n```json\n    {\n      \"overlay\" : {\n        \"active\"  : [\n          ...\n        ]\n      }\n    }\n```\n\nAnd there are various forms for each element (connected peer) in `active`:\n\n* With `\"ip\"` and `\"type\" : \"in\"`\n```json\n    {\n      \"ip\": \"24.234.130.12\",\n      \"public_key\": \"A2JwZ1y3iHno7/faxWfuhLF1skYPhMeLgURxyUzLT93B\",\n      \"type\": \"in\",\n      \"version\": \"rippled-0.28.0-b21\"\n    },\n```\n\n* With `\"ip\"` and `\"type\" : \"out\"` and `\"port\"`\n```json\n    {\n      \"ip\": \"54.186.73.52\",\n      \"port\": \"51235\",\n      \"public_key\": \"AjikFnq0P2XybCyREr2KPiqXqJteqwPwVRVbVK+93+3o\",\n      \"type\": \"out\",\n      \"version\": \"rippled-0.28.0-rc3\"\n    },\n```\n\n* With `\"ip\"` and `\"type\": \"peer``\n  * Without a port packed in `ip`, the `type` is actually `\"in\"`\n```json\n    {\n      \"ip\": \"54.164.144.101\",\n      \"public_key\": \"A8vPtayIaLdyV/2gLkWigyr1vwK2qqrre8ABRh2sXmMT\",\n      \"type\": \"peer\",\n      \"version\": \"rippled-0.28.0\"\n    },\n```\n\n* With `\"ip\"` (with a port)  and `\"type\": \"peer``\n  * With a port packed in `ip`, the `type` is  `\"out\"`\n```json\n    {\n      \"ip\": \"23.239.3.247:51235\",\n      \"public_key\": \"An366bc/eRsF01nmfnz6j2JnBA7gpSr7BCVygePEoWgs\",\n      \"type\": \"peer\",\n      \"version\": \"rippled-0.28.1-b5\"\n    },\n```\n\n* With only `\"public_key\"\" to identify node.\n\n  * Unfortunately we don't know the direction of the connection in these cases\n    but sometimes we have the direction information from another peers\n    perspective. We may also have the ip from another peers POV.\n```json\n    {\n      \"public_key\": \"An2mhwWHnwzBehh88G+vpwwwqviFAqMl9rjU2PnDELr9\",\n      \"type\": \"peer\",\n      \"version\": \"rippled-0.28.0-rc3\"\n    },\n```\n",
  "readmeFilename": "README.md",
  "gitHead": "eb7c5572be2c07ab883575733eff2898ef67811e",
  "_id": "rippled-network-crawler@0.3.0",
  "_shasum": "9dfb1bc181cd44c2032da6b115af31e090e44afb",
  "_from": "rippled-network-crawler@>=0.3.0 <0.4.0"
}
